{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây chúng tôi sẽ train trên 5 mô hình để tìm ra mô hình mang lại độ chính xác lớn nhất để sử dụng gồm: \n",
    "- LightGBM\n",
    "- XGBoost\n",
    "- RandomForest\n",
    "- GradientBoost\n",
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo các preprocessors cho mô hình tree và linear\n",
    "pre_tree, pre_lin = build_preprocessors(X_train)\n",
    "pre_tree.fit(X_train)\n",
    "X_val_tree = pre_tree.transform(X_val)\n",
    "cls_weight_dict, sample_weight_train = make_class_weight(y_train) # normalize frequency các class đầu ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng tôi sử dụng GridSearchCV để chạy nhiều lần lặp giúp mô hình tìm được parameter phù hợp và tối ưu nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các model và hyperparameters\n",
    "models = {\n",
    "    \"LightGBM\": (\n",
    "        LGBMClassifier(objective='multiclass', metric='multi_logloss', \n",
    "                        class_weight = cls_weight_dict, device='gpu', random_state=42,\n",
    "                        callbacks=[lgb_early_stop(stopping_rounds=50, first_metric_only=True, verbose=False)]),\n",
    "        { \"model__num_leaves\":       randint(31, 512),\n",
    "            \"model__max_depth\":        [-1, 7, 11, 15, 19],\n",
    "            \"model__learning_rate\":    uniform(0.01, 0.29),\n",
    "            \"model__n_estimators\":     randint(200, 801),\n",
    "            \"model__min_child_samples\":randint(10, 200) },\n",
    "        pre_tree,\n",
    "        {\"model__eval_set\":[(X_val_tree,y_val)]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(objective='multi:softprob',\n",
    "                        tree_method='hist', device = 'cuda', eval_metric='mlogloss',\n",
    "                        random_state=42, callbacks=[xgb_early_stop(rounds=50, metric_name='mlogloss', data_name ='validation_0', save_best=False)]),\n",
    "        { \"model__max_depth\":        randint(3, 12),\n",
    "            \"model__learning_rate\":    uniform(0.01, 0.29),\n",
    "            \"model__n_estimators\":     randint(200, 800),\n",
    "            \"model__subsample\":        uniform(0.6, 0.4),\n",
    "            \"model__colsample_bytree\": uniform(0.6, 0.4) },\n",
    "        pre_tree,\n",
    "        {\"model__eval_set\":[(X_val_tree,y_val)]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=cls_weight_dict,\n",
    "                                n_jobs=-1, random_state=42),\n",
    "        { \"model__n_estimators\":     randint(200,800),\n",
    "            \"model__max_depth\":        [None, 10, 20, 30],\n",
    "            \"model__min_samples_split\":randint(2,20),\n",
    "            \"model__min_samples_leaf\": randint(1,10) },\n",
    "        pre_tree,\n",
    "        {}\n",
    "    ),\n",
    "    \"GradientBoost\": (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        { \"model__learning_rate\":    uniform(0.01,0.29),\n",
    "            \"model__n_estimators\":     randint(100,600),\n",
    "            \"model__max_depth\":        randint(2,7),\n",
    "            \"model__subsample\":        uniform(0.5,0.5) },\n",
    "        pre_tree,\n",
    "        {}\n",
    "    ),\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=4000, multi_class='multinomial',\n",
    "                            n_jobs=-1),\n",
    "        { \"model__C\":        uniform(0.01, 100),\n",
    "            \"model__penalty\":  ['l2','none'],\n",
    "            \"model__solver\":   ['lbfgs','saga'] },\n",
    "        pre_lin,\n",
    "        {}\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và chúng tôi thêm Randomized search CV để giảm số lần lặp train model nhưng vẫn giữ độ chính xác tốt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate các model, và lưu lại model tốt nhất trên tập val\n",
    "tscv   = TimeSeriesSplit(n_splits=3)\n",
    "best_pipe, best_score, best_name = None, -1, \"\"\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for name,(est,dist,prep,fit_kw) in models.items():\n",
    "    n_iter = 30 if name in {\"RandomForest\", \"GradientBoost\"} else 50\n",
    "    print(f\"\\n▶▶ {name}: Randomized search ({n_iter} configs, 3-fold)\")\n",
    "    \n",
    "    pipe = Pipeline([('prep', prep), ('model', est)])\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe, dist, n_iter=n_iter, cv=tscv,\n",
    "        scoring='accuracy', n_jobs=-1, random_state=42, verbose=1, refit=True\n",
    "    )\n",
    "    \n",
    "    tic = time.time()\n",
    "    search.fit(X_train, y_train, **fit_kw)\n",
    "    toc = time.time()\n",
    "    print(f\"↳ Done in {(toc-tic)/60:.1f} min — best Acc={search.best_score_:.4f}\")\n",
    "\n",
    "    # Lưu hyperparameters tốt nhất\n",
    "    with open(f\"models/{name}_best.json\", \"w\") as fp:\n",
    "        json.dump(search.best_params_, fp, indent=2, default=str)\n",
    "\n",
    "    # In top-5 cấu hình tốt nhất\n",
    "    top5 = (pd.DataFrame(search.cv_results_)\n",
    "            .sort_values(\"rank_test_score\")\n",
    "            .head(5)[[\"mean_test_score\", \"params\"]])\n",
    "    print(top5.to_string(index=False))\n",
    "    \n",
    "    # Đánh giá trên tập val (season 2014/2015)\n",
    "    y_pred = search.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "    # Cập nhật best\n",
    "    if acc > best_score:\n",
    "        best_score, best_pipe, best_name = acc, search.best_estimator_, name\n",
    "\n",
    "    # Lưu checkpoint (chứa cả pipeline + preprocessors)\n",
    "    joblib.dump(search.best_estimator_, f\"models/{name}_best.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trên tập test 2015/2016\n",
    "if best_pipe is None:\n",
    "    raise RuntimeError(\"Không có mô hình nào huấn luyện thành công!\")\n",
    "\n",
    "print(f\"\\nBest model = {best_name}  (val Acc={best_score:.4f})\")\n",
    "y_test_pred = best_pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
